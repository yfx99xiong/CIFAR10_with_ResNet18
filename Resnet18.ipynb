{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "B3NPT02n6eac",
    "outputId": "3048ccd1-6f60-4b91-cd47-19cecf064cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU? True\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1, Training Accuracy: 0.39332, Test Accuracy: 0.4012\n",
      "Epoch: 2, Training Accuracy: 0.52894, Test Accuracy: 0.5262\n",
      "Epoch: 3, Training Accuracy: 0.59896, Test Accuracy: 0.5935\n",
      "Epoch: 4, Training Accuracy: 0.66724, Test Accuracy: 0.6601\n",
      "Epoch: 5, Training Accuracy: 0.6735, Test Accuracy: 0.6774\n",
      "Epoch: 6, Training Accuracy: 0.7076, Test Accuracy: 0.7066\n",
      "Epoch: 7, Training Accuracy: 0.74616, Test Accuracy: 0.7349\n",
      "Epoch: 8, Training Accuracy: 0.70476, Test Accuracy: 0.6878\n",
      "Epoch: 9, Training Accuracy: 0.7955, Test Accuracy: 0.7884\n",
      "Epoch: 10, Training Accuracy: 0.81698, Test Accuracy: 0.8144\n",
      "Epoch: 11, Training Accuracy: 0.80746, Test Accuracy: 0.7962\n",
      "Epoch: 12, Training Accuracy: 0.71464, Test Accuracy: 0.6925\n",
      "Epoch: 13, Training Accuracy: 0.8179, Test Accuracy: 0.8071\n",
      "Epoch: 14, Training Accuracy: 0.81694, Test Accuracy: 0.7924\n",
      "Epoch: 15, Training Accuracy: 0.75828, Test Accuracy: 0.7411\n",
      "Epoch: 16, Training Accuracy: 0.79924, Test Accuracy: 0.7862\n",
      "Epoch: 17, Training Accuracy: 0.80648, Test Accuracy: 0.802\n",
      "Epoch: 18, Training Accuracy: 0.8305, Test Accuracy: 0.8091\n",
      "Epoch: 19, Training Accuracy: 0.83152, Test Accuracy: 0.8091\n",
      "Epoch: 20, Training Accuracy: 0.76498, Test Accuracy: 0.7364\n",
      "Epoch: 21, Training Accuracy: 0.82766, Test Accuracy: 0.8148\n",
      "Epoch: 22, Training Accuracy: 0.82268, Test Accuracy: 0.813\n",
      "Epoch: 23, Training Accuracy: 0.78464, Test Accuracy: 0.7629\n",
      "Epoch: 24, Training Accuracy: 0.84562, Test Accuracy: 0.828\n",
      "Epoch: 25, Training Accuracy: 0.86328, Test Accuracy: 0.8435\n",
      "Epoch: 26, Training Accuracy: 0.87748, Test Accuracy: 0.8612\n",
      "Epoch: 27, Training Accuracy: 0.84638, Test Accuracy: 0.8182\n",
      "Epoch: 28, Training Accuracy: 0.80572, Test Accuracy: 0.7846\n",
      "Epoch: 29, Training Accuracy: 0.86526, Test Accuracy: 0.851\n",
      "Epoch: 30, Training Accuracy: 0.8159, Test Accuracy: 0.7974\n",
      "Epoch: 31, Training Accuracy: 0.83362, Test Accuracy: 0.816\n",
      "Epoch: 32, Training Accuracy: 0.82128, Test Accuracy: 0.794\n",
      "Epoch: 33, Training Accuracy: 0.84764, Test Accuracy: 0.8299\n",
      "Epoch: 34, Training Accuracy: 0.87802, Test Accuracy: 0.8597\n",
      "Epoch: 35, Training Accuracy: 0.82558, Test Accuracy: 0.8107\n",
      "Epoch: 36, Training Accuracy: 0.86294, Test Accuracy: 0.8466\n",
      "Epoch: 37, Training Accuracy: 0.84724, Test Accuracy: 0.8307\n",
      "Epoch: 38, Training Accuracy: 0.84896, Test Accuracy: 0.8283\n",
      "Epoch: 39, Training Accuracy: 0.82618, Test Accuracy: 0.8033\n",
      "Epoch: 40, Training Accuracy: 0.86176, Test Accuracy: 0.8463\n",
      "Epoch: 41, Training Accuracy: 0.86274, Test Accuracy: 0.8394\n",
      "Epoch: 42, Training Accuracy: 0.8167, Test Accuracy: 0.7959\n",
      "Epoch: 43, Training Accuracy: 0.88446, Test Accuracy: 0.8601\n",
      "Epoch: 44, Training Accuracy: 0.86052, Test Accuracy: 0.8456\n",
      "Epoch: 45, Training Accuracy: 0.8556, Test Accuracy: 0.8319\n",
      "Epoch: 46, Training Accuracy: 0.89494, Test Accuracy: 0.8737\n",
      "Epoch: 47, Training Accuracy: 0.85944, Test Accuracy: 0.8419\n",
      "Epoch: 48, Training Accuracy: 0.81402, Test Accuracy: 0.7954\n",
      "Epoch: 49, Training Accuracy: 0.85978, Test Accuracy: 0.8386\n",
      "Epoch: 50, Training Accuracy: 0.8811, Test Accuracy: 0.8638\n",
      "Epoch: 51, Training Accuracy: 0.8644, Test Accuracy: 0.8367\n",
      "Epoch: 52, Training Accuracy: 0.87638, Test Accuracy: 0.86\n",
      "Epoch: 53, Training Accuracy: 0.87944, Test Accuracy: 0.8532\n",
      "Epoch: 54, Training Accuracy: 0.88072, Test Accuracy: 0.8549\n",
      "Epoch: 55, Training Accuracy: 0.84594, Test Accuracy: 0.8298\n",
      "Epoch: 56, Training Accuracy: 0.82484, Test Accuracy: 0.8028\n",
      "Epoch: 57, Training Accuracy: 0.87368, Test Accuracy: 0.8486\n",
      "Epoch: 58, Training Accuracy: 0.86468, Test Accuracy: 0.8404\n",
      "Epoch: 59, Training Accuracy: 0.83522, Test Accuracy: 0.8053\n",
      "Epoch: 60, Training Accuracy: 0.86196, Test Accuracy: 0.8353\n",
      "Epoch: 61, Training Accuracy: 0.84626, Test Accuracy: 0.8323\n",
      "Epoch: 62, Training Accuracy: 0.8566, Test Accuracy: 0.8373\n",
      "Epoch: 63, Training Accuracy: 0.87828, Test Accuracy: 0.8571\n",
      "Epoch: 64, Training Accuracy: 0.87716, Test Accuracy: 0.8514\n",
      "Epoch: 65, Training Accuracy: 0.85066, Test Accuracy: 0.8334\n",
      "Epoch: 66, Training Accuracy: 0.83142, Test Accuracy: 0.8091\n",
      "Epoch: 67, Training Accuracy: 0.82002, Test Accuracy: 0.7955\n",
      "Epoch: 68, Training Accuracy: 0.86506, Test Accuracy: 0.8447\n",
      "Epoch: 69, Training Accuracy: 0.88744, Test Accuracy: 0.8596\n",
      "Epoch: 70, Training Accuracy: 0.84128, Test Accuracy: 0.8188\n",
      "Epoch: 71, Training Accuracy: 0.87528, Test Accuracy: 0.8502\n",
      "Epoch: 72, Training Accuracy: 0.88952, Test Accuracy: 0.8674\n",
      "Epoch: 73, Training Accuracy: 0.83982, Test Accuracy: 0.8214\n",
      "Epoch: 74, Training Accuracy: 0.86608, Test Accuracy: 0.8436\n",
      "Epoch: 75, Training Accuracy: 0.89632, Test Accuracy: 0.8648\n",
      "Epoch: 76, Training Accuracy: 0.85878, Test Accuracy: 0.8328\n",
      "Epoch: 77, Training Accuracy: 0.84546, Test Accuracy: 0.8221\n",
      "Epoch: 78, Training Accuracy: 0.8609, Test Accuracy: 0.8393\n",
      "Epoch: 79, Training Accuracy: 0.88092, Test Accuracy: 0.8598\n",
      "Epoch: 80, Training Accuracy: 0.87478, Test Accuracy: 0.8502\n",
      "Epoch: 81, Training Accuracy: 0.876, Test Accuracy: 0.8497\n",
      "Epoch: 82, Training Accuracy: 0.8705, Test Accuracy: 0.8444\n",
      "Epoch: 83, Training Accuracy: 0.87688, Test Accuracy: 0.8532\n",
      "Epoch: 84, Training Accuracy: 0.86584, Test Accuracy: 0.8451\n",
      "Epoch: 85, Training Accuracy: 0.8608, Test Accuracy: 0.8367\n",
      "Epoch: 86, Training Accuracy: 0.83072, Test Accuracy: 0.8083\n",
      "Epoch: 87, Training Accuracy: 0.87148, Test Accuracy: 0.8456\n",
      "Epoch: 88, Training Accuracy: 0.83556, Test Accuracy: 0.8146\n",
      "Epoch: 89, Training Accuracy: 0.88212, Test Accuracy: 0.8558\n",
      "Epoch: 90, Training Accuracy: 0.85162, Test Accuracy: 0.8232\n",
      "Epoch: 91, Training Accuracy: 0.87172, Test Accuracy: 0.8423\n",
      "Epoch: 92, Training Accuracy: 0.86538, Test Accuracy: 0.8418\n",
      "Epoch: 93, Training Accuracy: 0.86178, Test Accuracy: 0.8407\n",
      "Epoch: 94, Training Accuracy: 0.8454, Test Accuracy: 0.8124\n",
      "Epoch: 95, Training Accuracy: 0.87908, Test Accuracy: 0.8511\n",
      "Epoch: 96, Training Accuracy: 0.85348, Test Accuracy: 0.8365\n",
      "Epoch: 97, Training Accuracy: 0.88718, Test Accuracy: 0.8655\n",
      "Epoch: 98, Training Accuracy: 0.80074, Test Accuracy: 0.7761\n",
      "Epoch: 99, Training Accuracy: 0.85206, Test Accuracy: 0.8351\n",
      "Epoch: 100, Training Accuracy: 0.88038, Test Accuracy: 0.856\n",
      "Epoch: 101, Training Accuracy: 0.8693, Test Accuracy: 0.8475\n",
      "Epoch: 102, Training Accuracy: 0.88014, Test Accuracy: 0.8629\n",
      "Epoch: 103, Training Accuracy: 0.83586, Test Accuracy: 0.8136\n",
      "Epoch: 104, Training Accuracy: 0.8789, Test Accuracy: 0.8596\n",
      "Epoch: 105, Training Accuracy: 0.8127, Test Accuracy: 0.7787\n",
      "Epoch: 106, Training Accuracy: 0.85646, Test Accuracy: 0.8377\n",
      "Epoch: 107, Training Accuracy: 0.84534, Test Accuracy: 0.8302\n",
      "Epoch: 108, Training Accuracy: 0.8844, Test Accuracy: 0.8609\n",
      "Epoch: 109, Training Accuracy: 0.86256, Test Accuracy: 0.8512\n",
      "Epoch: 110, Training Accuracy: 0.82318, Test Accuracy: 0.7991\n",
      "Epoch: 111, Training Accuracy: 0.88584, Test Accuracy: 0.8684\n",
      "Epoch: 112, Training Accuracy: 0.86116, Test Accuracy: 0.842\n",
      "Epoch: 113, Training Accuracy: 0.86998, Test Accuracy: 0.8529\n",
      "Epoch: 114, Training Accuracy: 0.87694, Test Accuracy: 0.8552\n",
      "Epoch: 115, Training Accuracy: 0.86834, Test Accuracy: 0.8472\n",
      "Epoch: 116, Training Accuracy: 0.88032, Test Accuracy: 0.8564\n",
      "Epoch: 117, Training Accuracy: 0.8828, Test Accuracy: 0.8571\n",
      "Epoch: 118, Training Accuracy: 0.88268, Test Accuracy: 0.8544\n",
      "Epoch: 119, Training Accuracy: 0.8617, Test Accuracy: 0.8378\n",
      "Epoch: 120, Training Accuracy: 0.86272, Test Accuracy: 0.8292\n",
      "Total Computation Time: 4789.736839612\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Use GPU?', use_cuda)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                                          nn.BatchNorm2d(planes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out    \n",
    "\n",
    "minibatch_size = 128\n",
    "num_epochs = 120\n",
    "lr = 0.1\n",
    "\n",
    "# Define a model\n",
    "my_model = ResNet(BasicBlock, [2,2,2,2], num_classes=10) #ResNet18\n",
    "\n",
    "if use_cuda:\n",
    "    my_model = my_model.cuda()\n",
    "\n",
    "# Define a loss function and training algorithm\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=lr, momentum=0.9, weight_decay = 0.0005)\n",
    "\n",
    "\n",
    "#load dataset\n",
    "normalize = torchvision.transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                                                  torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                                  torchvision.transforms.ToTensor(),\n",
    "                                                  normalize])\n",
    "\n",
    "transform_test  = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),normalize])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=minibatch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=minibatch_size, shuffle=False)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "start = timer()\n",
    "\n",
    "#Train the NNs\n",
    "# One epoch is when an entire dataset is passed through the neural network only once.\n",
    "for epoch in range(num_epochs):\n",
    "#    current_lr = adjust_learning_rate(optimizer, epoch, lr)\n",
    "\n",
    "    my_model.train()\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # Forward pass to get the loss\n",
    "        outputs = my_model(images) \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and compute the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  #backpropragation\n",
    "        optimizer.step() #update the weights/parameters\n",
    "        \n",
    "  # Training accuracy\n",
    "    my_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        with torch.no_grad():\n",
    "          if use_cuda:\n",
    "              images = images.cuda()\n",
    "              labels = labels.cuda()  \n",
    "          outputs = my_model(images)\n",
    "          p_max, predicted = torch.max(outputs, 1) \n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum()\n",
    "    training_accuracy = float(correct)/total\n",
    "\n",
    "    \n",
    "    # Test accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "          if use_cuda:\n",
    "              images = images.cuda()\n",
    "              labels = labels.cuda()\n",
    "          outputs = my_model(images)\n",
    "          p_max, predicted = torch.max(outputs, 1) \n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum()\n",
    "    test_accuracy = float(correct)/total\n",
    "        \n",
    "    print('Epoch: {}, Training Accuracy: {}, Test Accuracy: {}' .format(epoch+1,training_accuracy,test_accuracy)) \n",
    "\n",
    "end = timer()\n",
    "print('Total Computation Time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rAkJpyUr5K3r",
    "outputId": "2a5c7bd4-6912-4611-8339-b6f1e66a6a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU? True\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1, learning rate: 0.1, the training accuracy: 0.39662, the test accuracy: 0.4032\n",
      "Epoch: 2, learning rate: 0.1, the training accuracy: 0.46072, the test accuracy: 0.4655\n",
      "Epoch: 3, learning rate: 0.1, the training accuracy: 0.61824, the test accuracy: 0.6141\n",
      "Epoch: 4, learning rate: 0.1, the training accuracy: 0.65456, the test accuracy: 0.6523\n",
      "Epoch: 5, learning rate: 0.1, the training accuracy: 0.72758, the test accuracy: 0.722\n",
      "Epoch: 6, learning rate: 0.1, the training accuracy: 0.7596, the test accuracy: 0.7559\n",
      "Epoch: 7, learning rate: 0.1, the training accuracy: 0.79408, the test accuracy: 0.7802\n",
      "Epoch: 8, learning rate: 0.1, the training accuracy: 0.76492, the test accuracy: 0.7566\n",
      "Epoch: 9, learning rate: 0.1, the training accuracy: 0.8095, the test accuracy: 0.802\n",
      "Epoch: 10, learning rate: 0.1, the training accuracy: 0.81336, the test accuracy: 0.7972\n",
      "Epoch: 11, learning rate: 0.1, the training accuracy: 0.82104, the test accuracy: 0.8126\n",
      "Epoch: 12, learning rate: 0.1, the training accuracy: 0.8077, the test accuracy: 0.7889\n",
      "Epoch: 13, learning rate: 0.1, the training accuracy: 0.79398, the test accuracy: 0.7761\n",
      "Epoch: 14, learning rate: 0.1, the training accuracy: 0.82158, the test accuracy: 0.8062\n",
      "Epoch: 15, learning rate: 0.1, the training accuracy: 0.79396, the test accuracy: 0.7753\n",
      "Epoch: 16, learning rate: 0.1, the training accuracy: 0.72244, the test accuracy: 0.6951\n",
      "Epoch: 17, learning rate: 0.1, the training accuracy: 0.8111, the test accuracy: 0.7967\n",
      "Epoch: 18, learning rate: 0.1, the training accuracy: 0.81792, the test accuracy: 0.8039\n",
      "Epoch: 19, learning rate: 0.1, the training accuracy: 0.85026, the test accuracy: 0.8307\n",
      "Epoch: 20, learning rate: 0.1, the training accuracy: 0.79266, the test accuracy: 0.7759\n",
      "Epoch: 21, learning rate: 0.1, the training accuracy: 0.8195, the test accuracy: 0.8029\n",
      "Epoch: 22, learning rate: 0.1, the training accuracy: 0.8279, the test accuracy: 0.8036\n",
      "Epoch: 23, learning rate: 0.1, the training accuracy: 0.84384, the test accuracy: 0.8282\n",
      "Epoch: 24, learning rate: 0.1, the training accuracy: 0.86734, the test accuracy: 0.8493\n",
      "Epoch: 25, learning rate: 0.1, the training accuracy: 0.86316, the test accuracy: 0.8441\n",
      "Epoch: 26, learning rate: 0.1, the training accuracy: 0.8278, the test accuracy: 0.814\n",
      "Epoch: 27, learning rate: 0.1, the training accuracy: 0.86132, the test accuracy: 0.8404\n",
      "Epoch: 28, learning rate: 0.1, the training accuracy: 0.8439, the test accuracy: 0.8159\n",
      "Epoch: 29, learning rate: 0.1, the training accuracy: 0.86066, the test accuracy: 0.8421\n",
      "Epoch: 30, learning rate: 0.1, the training accuracy: 0.87388, the test accuracy: 0.8515\n",
      "Epoch: 31, learning rate: 0.010000000000000002, the training accuracy: 0.94942, the test accuracy: 0.916\n",
      "Epoch: 32, learning rate: 0.010000000000000002, the training accuracy: 0.95844, the test accuracy: 0.9201\n",
      "Epoch: 33, learning rate: 0.010000000000000002, the training accuracy: 0.9642, the test accuracy: 0.9219\n",
      "Epoch: 34, learning rate: 0.010000000000000002, the training accuracy: 0.9679, the test accuracy: 0.9265\n",
      "Epoch: 35, learning rate: 0.010000000000000002, the training accuracy: 0.97102, the test accuracy: 0.9253\n",
      "Epoch: 36, learning rate: 0.010000000000000002, the training accuracy: 0.97246, the test accuracy: 0.9239\n",
      "Epoch: 37, learning rate: 0.010000000000000002, the training accuracy: 0.97588, the test accuracy: 0.9269\n",
      "Epoch: 38, learning rate: 0.010000000000000002, the training accuracy: 0.97864, the test accuracy: 0.9304\n",
      "Epoch: 39, learning rate: 0.010000000000000002, the training accuracy: 0.98054, the test accuracy: 0.9257\n",
      "Epoch: 40, learning rate: 0.010000000000000002, the training accuracy: 0.98144, the test accuracy: 0.925\n",
      "Epoch: 41, learning rate: 0.010000000000000002, the training accuracy: 0.98112, the test accuracy: 0.9262\n",
      "Epoch: 42, learning rate: 0.010000000000000002, the training accuracy: 0.98364, the test accuracy: 0.9256\n",
      "Epoch: 43, learning rate: 0.010000000000000002, the training accuracy: 0.98584, the test accuracy: 0.9245\n",
      "Epoch: 44, learning rate: 0.010000000000000002, the training accuracy: 0.98864, the test accuracy: 0.9258\n",
      "Epoch: 45, learning rate: 0.010000000000000002, the training accuracy: 0.987, the test accuracy: 0.9308\n",
      "Epoch: 46, learning rate: 0.010000000000000002, the training accuracy: 0.98224, the test accuracy: 0.9286\n",
      "Epoch: 47, learning rate: 0.010000000000000002, the training accuracy: 0.98658, the test accuracy: 0.9258\n",
      "Epoch: 48, learning rate: 0.010000000000000002, the training accuracy: 0.98664, the test accuracy: 0.9235\n",
      "Epoch: 49, learning rate: 0.010000000000000002, the training accuracy: 0.9858, the test accuracy: 0.9247\n",
      "Epoch: 50, learning rate: 0.010000000000000002, the training accuracy: 0.97952, the test accuracy: 0.9179\n",
      "Epoch: 51, learning rate: 0.010000000000000002, the training accuracy: 0.984, the test accuracy: 0.9235\n",
      "Epoch: 52, learning rate: 0.010000000000000002, the training accuracy: 0.98568, the test accuracy: 0.9249\n",
      "Epoch: 53, learning rate: 0.010000000000000002, the training accuracy: 0.98276, the test accuracy: 0.9213\n",
      "Epoch: 54, learning rate: 0.010000000000000002, the training accuracy: 0.98892, the test accuracy: 0.9293\n",
      "Epoch: 55, learning rate: 0.010000000000000002, the training accuracy: 0.98866, the test accuracy: 0.9273\n",
      "Epoch: 56, learning rate: 0.010000000000000002, the training accuracy: 0.98542, the test accuracy: 0.9244\n",
      "Epoch: 57, learning rate: 0.010000000000000002, the training accuracy: 0.98326, the test accuracy: 0.9151\n",
      "Epoch: 58, learning rate: 0.010000000000000002, the training accuracy: 0.98158, the test accuracy: 0.9154\n",
      "Epoch: 59, learning rate: 0.010000000000000002, the training accuracy: 0.98604, the test accuracy: 0.9194\n",
      "Epoch: 60, learning rate: 0.010000000000000002, the training accuracy: 0.97904, the test accuracy: 0.9138\n",
      "Epoch: 61, learning rate: 0.0010000000000000002, the training accuracy: 0.99656, the test accuracy: 0.9349\n",
      "Epoch: 62, learning rate: 0.0010000000000000002, the training accuracy: 0.99804, the test accuracy: 0.9364\n",
      "Epoch: 63, learning rate: 0.0010000000000000002, the training accuracy: 0.9984, the test accuracy: 0.9366\n",
      "Epoch: 64, learning rate: 0.0010000000000000002, the training accuracy: 0.99848, the test accuracy: 0.938\n",
      "Epoch: 65, learning rate: 0.0010000000000000002, the training accuracy: 0.99884, the test accuracy: 0.9381\n",
      "Epoch: 66, learning rate: 0.0010000000000000002, the training accuracy: 0.99884, the test accuracy: 0.9381\n",
      "Epoch: 67, learning rate: 0.0010000000000000002, the training accuracy: 0.99902, the test accuracy: 0.9372\n",
      "Epoch: 68, learning rate: 0.0010000000000000002, the training accuracy: 0.9993, the test accuracy: 0.9372\n",
      "Epoch: 69, learning rate: 0.0010000000000000002, the training accuracy: 0.99924, the test accuracy: 0.9381\n",
      "Epoch: 70, learning rate: 0.0010000000000000002, the training accuracy: 0.99922, the test accuracy: 0.9384\n",
      "Epoch: 71, learning rate: 0.0010000000000000002, the training accuracy: 0.99924, the test accuracy: 0.9385\n",
      "Epoch: 72, learning rate: 0.0010000000000000002, the training accuracy: 0.99968, the test accuracy: 0.9397\n",
      "Epoch: 73, learning rate: 0.0010000000000000002, the training accuracy: 0.99948, the test accuracy: 0.9382\n",
      "Epoch: 74, learning rate: 0.0010000000000000002, the training accuracy: 0.99946, the test accuracy: 0.9389\n",
      "Epoch: 75, learning rate: 0.0010000000000000002, the training accuracy: 0.99958, the test accuracy: 0.9405\n",
      "Epoch: 76, learning rate: 0.0010000000000000002, the training accuracy: 0.9997, the test accuracy: 0.9391\n",
      "Epoch: 77, learning rate: 0.0010000000000000002, the training accuracy: 0.99958, the test accuracy: 0.9395\n",
      "Epoch: 78, learning rate: 0.0010000000000000002, the training accuracy: 0.99964, the test accuracy: 0.9389\n",
      "Epoch: 79, learning rate: 0.0010000000000000002, the training accuracy: 0.99972, the test accuracy: 0.9387\n",
      "Epoch: 80, learning rate: 0.0010000000000000002, the training accuracy: 0.99982, the test accuracy: 0.9401\n",
      "Epoch: 81, learning rate: 0.0010000000000000002, the training accuracy: 0.99976, the test accuracy: 0.9398\n",
      "Epoch: 82, learning rate: 0.0010000000000000002, the training accuracy: 0.9997, the test accuracy: 0.939\n",
      "Epoch: 83, learning rate: 0.0010000000000000002, the training accuracy: 0.99976, the test accuracy: 0.9394\n",
      "Epoch: 84, learning rate: 0.0010000000000000002, the training accuracy: 0.99982, the test accuracy: 0.9409\n",
      "Epoch: 85, learning rate: 0.0010000000000000002, the training accuracy: 0.99978, the test accuracy: 0.9404\n",
      "Epoch: 86, learning rate: 0.0010000000000000002, the training accuracy: 0.99986, the test accuracy: 0.9392\n",
      "Epoch: 87, learning rate: 0.0010000000000000002, the training accuracy: 0.99988, the test accuracy: 0.9382\n",
      "Epoch: 88, learning rate: 0.0010000000000000002, the training accuracy: 0.99978, the test accuracy: 0.9386\n",
      "Epoch: 89, learning rate: 0.0010000000000000002, the training accuracy: 0.99976, the test accuracy: 0.9388\n",
      "Epoch: 90, learning rate: 0.0010000000000000002, the training accuracy: 0.99978, the test accuracy: 0.9389\n",
      "Epoch: 91, learning rate: 0.00010000000000000003, the training accuracy: 0.99986, the test accuracy: 0.9388\n",
      "Epoch: 92, learning rate: 0.00010000000000000003, the training accuracy: 0.99984, the test accuracy: 0.939\n",
      "Epoch: 93, learning rate: 0.00010000000000000003, the training accuracy: 0.99986, the test accuracy: 0.9385\n",
      "Epoch: 94, learning rate: 0.00010000000000000003, the training accuracy: 0.99994, the test accuracy: 0.9396\n",
      "Epoch: 95, learning rate: 0.00010000000000000003, the training accuracy: 0.99986, the test accuracy: 0.9387\n",
      "Epoch: 96, learning rate: 0.00010000000000000003, the training accuracy: 0.99988, the test accuracy: 0.9391\n",
      "Epoch: 97, learning rate: 0.00010000000000000003, the training accuracy: 0.99988, the test accuracy: 0.939\n",
      "Epoch: 98, learning rate: 0.00010000000000000003, the training accuracy: 0.99988, the test accuracy: 0.9383\n",
      "Epoch: 99, learning rate: 0.00010000000000000003, the training accuracy: 0.99992, the test accuracy: 0.9392\n",
      "Epoch: 100, learning rate: 0.00010000000000000003, the training accuracy: 0.99992, the test accuracy: 0.9385\n",
      "Epoch: 101, learning rate: 0.00010000000000000003, the training accuracy: 0.99978, the test accuracy: 0.9388\n",
      "Epoch: 102, learning rate: 0.00010000000000000003, the training accuracy: 0.99986, the test accuracy: 0.9389\n",
      "Epoch: 103, learning rate: 0.00010000000000000003, the training accuracy: 0.99988, the test accuracy: 0.9382\n",
      "Epoch: 104, learning rate: 0.00010000000000000003, the training accuracy: 0.99992, the test accuracy: 0.939\n",
      "Epoch: 105, learning rate: 0.00010000000000000003, the training accuracy: 0.99992, the test accuracy: 0.939\n",
      "Epoch: 106, learning rate: 0.00010000000000000003, the training accuracy: 0.99984, the test accuracy: 0.9391\n",
      "Epoch: 107, learning rate: 0.00010000000000000003, the training accuracy: 0.99988, the test accuracy: 0.939\n",
      "Epoch: 108, learning rate: 0.00010000000000000003, the training accuracy: 0.99994, the test accuracy: 0.9388\n",
      "Epoch: 109, learning rate: 0.00010000000000000003, the training accuracy: 0.99984, the test accuracy: 0.9391\n",
      "Epoch: 110, learning rate: 0.00010000000000000003, the training accuracy: 0.99988, the test accuracy: 0.9393\n",
      "Epoch: 111, learning rate: 0.00010000000000000003, the training accuracy: 0.99984, the test accuracy: 0.9388\n",
      "Epoch: 112, learning rate: 0.00010000000000000003, the training accuracy: 0.99984, the test accuracy: 0.9386\n",
      "Epoch: 113, learning rate: 0.00010000000000000003, the training accuracy: 0.99986, the test accuracy: 0.9396\n",
      "Epoch: 114, learning rate: 0.00010000000000000003, the training accuracy: 0.9998, the test accuracy: 0.9395\n",
      "Epoch: 115, learning rate: 0.00010000000000000003, the training accuracy: 0.9999, the test accuracy: 0.9388\n",
      "Epoch: 116, learning rate: 0.00010000000000000003, the training accuracy: 0.99982, the test accuracy: 0.9389\n",
      "Epoch: 117, learning rate: 0.00010000000000000003, the training accuracy: 0.99986, the test accuracy: 0.9388\n",
      "Epoch: 118, learning rate: 0.00010000000000000003, the training accuracy: 0.99992, the test accuracy: 0.9393\n",
      "Epoch: 119, learning rate: 0.00010000000000000003, the training accuracy: 0.99996, the test accuracy: 0.9389\n",
      "Epoch: 120, learning rate: 0.00010000000000000003, the training accuracy: 0.99994, the test accuracy: 0.9389\n",
      "Total Computation Time: 4869.761699983\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Use GPU?', use_cuda)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                                          nn.BatchNorm2d(planes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out    \n",
    "    \n",
    "def adjust_learning_rate(optimizer, epoch, init_lr):\n",
    "    #lr = 1.0 / (epoch + 1)\n",
    "    lr = init_lr * 0.1 ** (epoch // 30)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "minibatch_size = 128\n",
    "num_epochs = 120\n",
    "lr = 0.1\n",
    "\n",
    "# Step 1: Define a model\n",
    "my_model = ResNet(BasicBlock, [2,2,2,2], num_classes=10) #ResNet18\n",
    "\n",
    "if use_cuda:\n",
    "    my_model = my_model.cuda()\n",
    "\n",
    "# Step 2: Define a loss function and training algorithm\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=lr, momentum=0.9, weight_decay = 0.0005)\n",
    "\n",
    "\n",
    "# Step 3: load dataset\n",
    "normalize = torchvision.transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([torchvision.transforms.RandomCrop(32, padding=4),\n",
    "                                                  torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                                  torchvision.transforms.ToTensor(),\n",
    "                                                  normalize])\n",
    "\n",
    "transform_test  = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),normalize])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=minibatch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=minibatch_size, shuffle=False)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "start = timer()\n",
    "\n",
    "#Step 4: Train the NNs\n",
    "# One epoch is when an entire dataset is passed through the neural network only once.\n",
    "for epoch in range(num_epochs):\n",
    "    current_lr = adjust_learning_rate(optimizer, epoch, lr)\n",
    "\n",
    "    my_model.train()\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "          images = images.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "        # Forward pass to get the loss\n",
    "        outputs = my_model(images) \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and compute the gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  #backpropragation\n",
    "        optimizer.step() #update the weights/parameters\n",
    "        \n",
    "  # Training accuracy\n",
    "    my_model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        with torch.no_grad():\n",
    "          if use_cuda:\n",
    "              images = images.cuda()\n",
    "              labels = labels.cuda()  \n",
    "          outputs = my_model(images)\n",
    "          p_max, predicted = torch.max(outputs, 1) \n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum()\n",
    "    training_accuracy = float(correct)/total\n",
    "\n",
    "    \n",
    "    # Test accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(testloader):\n",
    "        with torch.no_grad():\n",
    "          if use_cuda:\n",
    "              images = images.cuda()\n",
    "              labels = labels.cuda()\n",
    "          outputs = my_model(images)\n",
    "          p_max, predicted = torch.max(outputs, 1) \n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum()\n",
    "    test_accuracy = float(correct)/total\n",
    "        \n",
    "    print('Epoch: {}, learning rate: {}, the training accuracy: {}, the test accuracy: {}' .format(epoch+1,current_lr,training_accuracy,test_accuracy)) \n",
    "\n",
    "end = timer()\n",
    "print('Total Computation Time:',end - start)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Coding5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
